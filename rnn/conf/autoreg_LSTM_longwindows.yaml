tr_data_fname: train_v4_rnn_nonorm_febtofeb_y1-7_stackedyear_nocompress_chunk3.h5
# tr_data_fname: train_v4_rnn_nonorm_febtofeb_y1-7_stackedhalfyear_gzip8_chunk1_subset.h5
# tr_data_fname: train_v4_rnn_nonorm_febtofeb_y1-7_stackedhalfyear_nocompress_chunk3.h5
#tr_data_fname: train_v4_rnn_nonorm_febtofeb_y1-7_stackedyear_nocompress_chunk3.h5
val_data_fname: data_v4_rnn_nonorm_year8_nocompress_chunk3.h5
tr_data_dir: "/data/phys-climsim/low-res-expanded/train/preprocessed/"
val_data_dir: "/data/phys-climsim/low-res-expanded/train/preprocessed/"
#tr_data_dir: "/media/peter/CrucialP1/data/ClimSim/low_res_expanded/"
#val_data_dir: "/media/peter/CrucialP1/data/ClimSim/low_res_expanded/"
#tr_data_dir: "/gpfs/projects/ehpc272/low_res_expanded/"
#val_data_dir: "/gpfs/projects/ehpc272/low_res_expanded/"
#tr_data_dir: "/data/ClimSim/"
#val_data_dir: "/data/ClimSim/"

checkpoint_path: ""

# cache option: during the first epoch, as the data is loaded it is put in shared (RAM) memory, 
# from which it is loaded in subsequent epochs
# this allows to use multiple workers and fast RAM memory without copying the data to each worker, 
# which is especially useful on systems without SSDs. If the data is on a fast SSD, there is no need
# to put the data in memory assuming multiple workers and prefetching is used
cache: true
val_cache: false 
num_workers: 4
chunksize_train: 24
chunksize_val: 14

batch_size_tr: 3840
batch_size_val: 384
val_epoch_start: 0

model_file_checkpoint: None

autoregressive: true
ar_noise_mode: 0
ar_tau: 0.85
mp_mode: 1
physical_precip: false
input_norm_per_level: true
output_norm_per_level: true
new_nolev_scaling: false
# loss_fn_type: mse
loss_fn_type: huber
use_energy_loss: true
# w_hcon: 1.0e-05
w_hcon: 6.0e-06
# input_norm_per_level: false
# output_norm_per_level: false
use_water_loss: true
w_wcon: 6.0e7
use_bias_loss: false
w_bias: 1.0e5
use_precip_accum_loss: false 
wprec_bias: 1.66e12
output_prune: true
qinput_prune: true
rh_prune: true
remove_past_sfc_inputs: true
v4_to_v5_inputs: false
include_prev_inputs: false
include_prev_outputs: false
use_surface_memory: false
snowhice_fix: true

nh_mem: 16
nneur:
- 160
- 160
cfc_nout: 24 

add_pres: true
add_refpres: false
add_stochastic_layer: false
use_initial_mlp: true
use_intermediate_mlp: true
memory: Hidden
model_type: LSTM
concat: false
separate_radiation: false
ensemble_size: 1 
crps_start_epoch: 0 
beta: 1.0 

lr_scheduler: OneCycleLR
scheduler_end_epoch: 95
scheduler_min_lr: 0.0000003
scheduler_max_lr: 0.0015
scheduler_peak_epoch: 4
scheduler_annealing: cos
lr_gamma: 0.95
save_model: true
use_wandb: true
num_epochs: 100
lr: 0.001
timestepped_optimizer: false
mp_autocast: true
use_scaler: true
shuffle_data: false
timestep_scheduling: true
optimizer: soap
#optimizer: adamwschedulefree
rollout_schedule:
- 1
- 2
- 3
- 3
- 4
- 4
- 5
- 5
- 6
- 6
swap_true_mem_with_pred_epoch: 0

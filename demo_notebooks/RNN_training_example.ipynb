{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6c3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from climsim_utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ac0ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_path = '../grid_info/ClimSim_low-res_grid-info.nc'\n",
    "norm_path = '../preprocessing/normalizations/'\n",
    "\n",
    "grid_info = xr.open_dataset(grid_path)\n",
    "input_mean = xr.open_dataset(norm_path + 'inputs/input_mean.nc').astype(np.float32)\n",
    "input_max = xr.open_dataset(norm_path + 'inputs/input_max.nc').astype(np.float32)\n",
    "input_min = xr.open_dataset(norm_path + 'inputs/input_min.nc').astype(np.float32)\n",
    "output_scale = xr.open_dataset(norm_path + 'outputs/output_scale.nc').astype(np.float32)\n",
    "\n",
    "ml_backend = 'pytorch'\n",
    "input_abbrev = 'mlexpand'\n",
    "output_abbrev = 'mlo'\n",
    "data = data_utils(grid_info = grid_info, \n",
    "                  input_mean = input_mean, \n",
    "                  input_max = input_max, \n",
    "                  input_min = input_min, \n",
    "                  output_scale = output_scale,\n",
    "                  ml_backend = ml_backend,\n",
    "                  normalize = True,\n",
    "                  input_abbrev = input_abbrev,\n",
    "                  output_abbrev = output_abbrev,\n",
    "                  save_h5=True,\n",
    "                  save_npy=False,\n",
    "                  )\n",
    "data.set_to_v2_vars()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b14bf830",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/network/group/aopp/predict/HMC009_UKKONEN_CLIMSIM/ClimSim_data/ClimSim_low-res-expanded/train/preprocessed/\"\n",
    "data_fname = \"train_first4months.h5\"\n",
    "\n",
    "data_path = data_dir + data_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "038d6ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['input_lev', 'input_sca', 'output_lev', 'output_sca']>\n",
      "<KeysViewHDF5 []>\n",
      "<KeysViewHDF5 []>\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File(data_path, 'r')\n",
    "print(hf.keys())\n",
    "# <KeysViewHDF5 ['input_lev', 'input_sca', 'output_lev', 'output_sca']>\n",
    "print(hf.attrs.keys())\n",
    "print(hf['input_lev'].attrs.keys())\n",
    "# future training data should have a \"varnames\" attribute for each dataset type \n",
    "\n",
    "#2D Input variables: ['state_t', 'state_q0001', 'state_q0002', 'state_q0003', 'state_u', 'state_v', \n",
    "# 'pbuf_ozone', 'pbuf_CH4', 'pbuf_N2O']\n",
    "# We need pressure!\n",
    "\n",
    "#1D (scalar) Input variables: ['state_ps', 'pbuf_SOLIN', 'pbuf_LHFLX', 'pbuf_SHFLX', 'pbuf_TAUX', \n",
    "# 'pbuf_TAUY', 'pbuf_COSZRS', 'cam_in_ALDIF', 'cam_in_ALDIR', 'cam_in_ASDIF', 'cam_in_ASDIR', \n",
    "# 'cam_in_LWUP', 'cam_in_ICEFRAC', 'cam_in_LANDFRAC', 'cam_in_OCNFRAC', 'cam_in_SNOWHICE', \n",
    "# 'cam_in_SNOWHLAND', 'lat', 'lon']\n",
    "\n",
    "#2D Output variables: ['ptend_t', 'ptend_q0001', 'ptend_q0002', 'ptend_q0003', 'ptend_u', 'ptend_v']\n",
    "\n",
    "#1D (scalar) Output variables: ['cam_out_NETSW', 'cam_out_FLWDS', 'cam_out_PRECSC', \n",
    "#'cam_out_PRECC', 'cam_out_SOLS', 'cam_out_SOLL', 'cam_out_SOLSD', 'cam_out_SOLLD']\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1ca7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(data_path, 'r')\n",
    "x_lay = hf['input_lev'][:]\n",
    "x_sfc = hf['input_sca'][:]\n",
    "y_lay = hf['output_lev'][:]\n",
    "y_sfc = hf['output_sca'][:]\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7843fd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316608, 60, 9) -0.9369526 1.0\n"
     ]
    }
   ],
   "source": [
    "print(x_lay.shape, x_lay.min(), x_lay.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b23b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3316608, 17) -0.8866354 0.96252674\n",
      "(3316608, 60, 6) -2.848058 3.7311456\n",
      "(3316608, 8) 0.0 2.592345\n"
     ]
    }
   ],
   "source": [
    "print(x_sfc.shape, x_sfc.min(), x_sfc.max())\n",
    "print(y_lay.shape, y_lay.min(), y_lay.max())\n",
    "print(y_sfc.shape, y_sfc.min(), y_sfc.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec536b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parameter as Parameter\n",
    "\n",
    "class MyRNN(nn.Module):\n",
    "    def __init__(self, RNN_type='LSTM', \n",
    "                 nx = 9, nx_sfc=17, \n",
    "                 ny = 8, ny_sfc=8, \n",
    "                 nneur=(64,64), \n",
    "                 outputs_one_longer=False, # if True, inputs are a sequence\n",
    "                 # of N and outputs a sequence of N+1 (e.g. predicting fluxes)\n",
    "                 concat=False):\n",
    "        # Simple bidirectional RNN (Either LSTM or GRU) for predicting column \n",
    "        # outputs shaped either (B, L, Ny) or (B, L+1, Ny) from column inputs\n",
    "        # (B, L, Nx) and optionally surface inputs (B, Nx_sfc) \n",
    "        # If surface inputs exist, they are used to initialize first (upward) RNN \n",
    "        # Assumes top-of-atmosphere is first in memory i.e. at index 0 \n",
    "        # if it's not the flip operations need to be moved!\n",
    "        super(MyRNN, self).__init__()\n",
    "        self.nx = nx\n",
    "        self.ny = ny \n",
    "        self.nx_sfc = nx_sfc \n",
    "        self.ny_sfc = ny_sfc\n",
    "        self.nneur = nneur \n",
    "        self.outputs_one_longer=outputs_one_longer\n",
    "        if len(nneur) < 1 or len(nneur) > 3:\n",
    "            sys.exit(\"Number of RNN layers and length of nneur should be 2 or 3\")\n",
    "\n",
    "        self.RNN_type=RNN_type\n",
    "        if self.RNN_type=='LSTM':\n",
    "            RNN_model = nn.LSTM\n",
    "        elif self.RNN_type=='GRU':\n",
    "            RNN_model = nn.GRU\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "                    \n",
    "        self.concat=concat\n",
    "\n",
    "        if self.nx_sfc > 0:\n",
    "            self.mlp_surface1  = nn.Linear(nx_sfc, self.nneur[0])\n",
    "            if self.RNN_type==\"LSTM\":\n",
    "                self.mlp_surface2  = nn.Linear(nx_sfc, self.nneur[0])\n",
    "\n",
    "        self.rnn1      = RNN_model(nx,            self.nneur[0], batch_first=True) # (input_size, hidden_size, num_layers=1\n",
    "        self.rnn2      = RNN_model(self.nneur[0], self.nneur[1], batch_first=True)\n",
    "        if len(self.nneur)==3:\n",
    "            self.rnn3      = RNN_model(self.nneur[1], self.nneur[2], batch_first=True)\n",
    "\n",
    "        # The final hidden variable is either the output from the last RNN, or\n",
    "        # the  concatenated outputs from all RNNs\n",
    "        if concat:\n",
    "            nh_rnn = sum(nneur)\n",
    "        else:\n",
    "            nh_rnn = nneur[-1]\n",
    "\n",
    "        self.mlp_output = nn.Linear(nh_rnn, self.ny)\n",
    "        if self.ny_sfc>0:\n",
    "            self.mlp_surface_output = nn.Linear(nneur[-1], self.ny_sfc)\n",
    "        \n",
    "            \n",
    "    def forward(self, inputs_main, inputs_sfc=None):\n",
    "            \n",
    "        # batch_size = inputs_main.shape[0]\n",
    "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "      \n",
    "        if inputs_sfc is not None:\n",
    "            sfc1 = self.mlp_surface1(inputs_sfc)\n",
    "            sfc1 = nn.Tanh()(sfc1)\n",
    "            \n",
    "            if self.RNN_type==\"LSTM\":\n",
    "                sfc2 = self.mlp_surface2(inputs_sfc)\n",
    "                sfc2 = nn.Tanh()(sfc2)\n",
    "                hidden = (sfc1.view(1,-1,self.nneur[0]), sfc2.view(1,-1,self.nneur[0])) # (h0, c0)\n",
    "            else:\n",
    "                hidden = (sfc1.view(1,-1,self.nneur[0]))\n",
    "        else:\n",
    "            hidden = None\n",
    "\n",
    "        # print(f'Using state1 {hidden}')\n",
    "        # TOA is first in memory, so we need to flip the axis\n",
    "        inputs_main = torch.flip(inputs_main, [1])\n",
    "      \n",
    "        out, hidden = self.rnn1(inputs_main, hidden)\n",
    "        \n",
    "        if self.outputs_one_longer:\n",
    "            out = torch.cat((sfc1, out),axis=1)\n",
    "\n",
    "        out = torch.flip(out, [1]) # the surface was processed first, but for\n",
    "        # the second RNN (and the final output) we want TOA first\n",
    "        \n",
    "        out2, hidden2 = self.rnn2(out) \n",
    "        \n",
    "        (last_h, last_c) = hidden2\n",
    "\n",
    "        if len(self.nneur)==3:\n",
    "            rnn3_input = torch.flip(out2, [1])\n",
    "            \n",
    "            out3, hidden3 = self.rnn3(rnn3_input) \n",
    "            \n",
    "            out3 = torch.flip(out3, [1])\n",
    "            \n",
    "            if self.concat:\n",
    "                rnnout = torch.cat((out3, out2, out),axis=2)\n",
    "            else:\n",
    "                rnnout = out3\n",
    "        else:\n",
    "            if self.concat:\n",
    "                rnnout = torch.cat((out2, out),axis=2)\n",
    "            else:\n",
    "                rnnout = out2\n",
    "        \n",
    "        out = self.mlp_output(rnnout)\n",
    "\n",
    "        if self.ny_sfc>0:\n",
    "            #print(\"shape last_c\", last_c.shape)\n",
    "            # use cell state or hidden state?\n",
    "            out_sfc = self.mlp_surface_output(last_h.squeeze())\n",
    "            return out, out_sfc\n",
    "        else:\n",
    "            return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd5e97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 60, 9]) torch.Size([10240, 17])\n",
      "torch.Size([10240, 60, 6]) torch.Size([10240, 8])\n"
     ]
    }
   ],
   "source": [
    "nb = 1024 \n",
    "\n",
    "x_lay0 = torch.from_numpy(x_lay[0:10*nb])\n",
    "x_sfc0 = torch.from_numpy(x_sfc[0:10*nb])\n",
    "y_lay0 = torch.from_numpy(y_lay[0:10*nb])\n",
    "y_sfc0 = torch.from_numpy(y_sfc[0:10*nb])\n",
    "\n",
    "print(x_lay0.shape, x_sfc0.shape)\n",
    "print(y_lay0.shape, y_sfc0.shape)\n",
    "\n",
    "ns, nlay, nx = x_lay0.shape\n",
    "_, nx_sfc    = x_sfc0.shape\n",
    "_, _, ny     = y_lay0.shape\n",
    "_, ny_sfc    = y_sfc0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa2f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 9\n",
    "nx_sfc = 17\n",
    "ny = 6\n",
    "ny_sfc = 8\n",
    "\n",
    "add_refpres = True\n",
    "if add_refpres:\n",
    "    nx = nx + 1\n",
    "\n",
    "model = MyRNN(RNN_type='LSTM', \n",
    "             nx = nx, nx_sfc=nx_sfc, \n",
    "             ny = ny, ny_sfc=ny_sfc, \n",
    "             nneur=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1261f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10240, 60, 6]) torch.Size([10240, 8])\n"
     ]
    }
   ],
   "source": [
    "out, out_sfc = model(x_lay0, x_sfc0)\n",
    "print(out.shape, out_sfc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c610834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape ps torch.Size([10240, 1]) min tensor(75208.2969) max tensor(102864.2344)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/user/28272/ipykernel_2837606/3482244970.py:4: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  state_ps = state_ps*(data.input_max['state_ps'].values - data.input_min['state_ps'].values) + data.input_mean['state_ps'].values\n"
     ]
    }
   ],
   "source": [
    "state_ps = x_sfc0[:,0:1]\n",
    "\n",
    "if data.normalize:\n",
    "    state_ps = state_ps*(data.input_max['state_ps'].values - data.input_min['state_ps'].values) + data.input_mean['state_ps'].values\n",
    "\n",
    "print(\"shape ps\", state_ps.shape, \"min\", state_ps.min(), \"max\", state_ps.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4682b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pressure_grid_p1 = np.array(data.grid_info['P0']*data.grid_info['hyai'])[:,np.newaxis,np.newaxis]\n",
    "pressure_grid_p1 = torch.from_numpy(np.array(data.grid_info['P0']*data.grid_info['hyai'])[np.newaxis,:])\n",
    "#print(pressure_grid_p1.shape)\n",
    "pressure_grid_p2 = torch.from_numpy(data.grid_info['hybi'].values[np.newaxis, :]) * state_ps\n",
    "#print(pressure_grid_p2.shape)\n",
    "pressure_grid = pressure_grid_p1 + pressure_grid_p2\n",
    "#print(pressure_grid.shape, pressure_grid.min(), pressure_grid.max())\n",
    "dp     = pressure_grid[:,1:61] - pressure_grid[:,0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b56fd439",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.array(data.grid_info['P0']*data.grid_info['hyam'])[np.newaxis,:] \n",
    "p2 = data.grid_info['hybm'].values[np.newaxis, :] * data.grid_info['P0'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "45bca02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.83478113e-02 1.41108318e-01 2.52923297e-01 4.49250635e-01\n",
      "  7.86346161e-01 1.34735576e+00 2.24477729e+00 3.61643148e+00\n",
      "  5.61583643e+00 8.40325322e+00 1.21444894e+01 1.70168280e+01\n",
      "  2.32107981e+01 3.09143463e+01 4.02775807e+01 5.13746323e+01\n",
      "  6.41892284e+01 7.86396576e+01 9.46300920e+01 1.12091274e+02\n",
      "  1.30977804e+02 1.51221318e+02 1.72673905e+02 1.95087710e+02\n",
      "  2.18155935e+02 2.41600379e+02 2.65258515e+02 2.89122322e+02\n",
      "  3.13312087e+02 3.38006999e+02 3.63373492e+02 3.89523338e+02\n",
      "  4.16507922e+02 4.44331412e+02 4.72957206e+02 5.02291917e+02\n",
      "  5.32152273e+02 5.62239392e+02 5.92149276e+02 6.21432841e+02\n",
      "  6.49689897e+02 6.76656485e+02 7.02242188e+02 7.26498589e+02\n",
      "  7.49537645e+02 7.71445217e+02 7.92234260e+02 8.11856675e+02\n",
      "  8.30259643e+02 8.47450653e+02 8.63535902e+02 8.78715875e+02\n",
      "  8.93246018e+02 9.07385213e+02 9.21354397e+02 9.35316717e+02\n",
      "  9.49378056e+02 9.63599599e+02 9.78013432e+02 9.92635544e+02]]\n"
     ]
    }
   ],
   "source": [
    "pref = p1 + p2 \n",
    "print(pref/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "147abd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator_xy(torch.utils.data.Dataset):\n",
    "    def __init__(self, filepath, nloc=384, nlev=60, add_refpres=True, cuda=False):\n",
    "        self.filepath = filepath\n",
    "        # The file list will be divided into chunks (a list of lists)eg [[12,4,32],[1,9,3]..]\n",
    "        # where the length of each item is the chunk size; i.e. how many files \n",
    "        # are loaded at once (in this example 3 files)\n",
    "        # self.chunk_size = chunk_size # how many batches are loaded at once in getitem\n",
    "        self.nloc = nloc\n",
    "        self.nlev = nlev\n",
    "        # self.nloc = int(os.path.basename(self.filepath).split('_')[-1])\n",
    "        # self.stateful = stateful\n",
    "        self.refpres = np.array([7.83478113e-02,1.41108318e-01,2.52923297e-01,4.49250635e-01,\n",
    "                    7.86346161e-01,1.34735576e+00,2.24477729e+00,3.61643148e+00,\n",
    "                    5.61583643e+00,8.40325322e+00,1.21444894e+01,1.70168280e+01,\n",
    "                    2.32107981e+01,3.09143463e+01,4.02775807e+01,5.13746323e+01,\n",
    "                    6.41892284e+01,7.86396576e+01,9.46300920e+01,1.12091274e+02,\n",
    "                    1.30977804e+02,1.51221318e+02,1.72673905e+02,1.95087710e+02,\n",
    "                    2.18155935e+02,2.41600379e+02,2.65258515e+02,2.89122322e+02,\n",
    "                    3.13312087e+02,3.38006999e+02,3.63373492e+02,3.89523338e+02,\n",
    "                    4.16507922e+02,4.44331412e+02,4.72957206e+02,5.02291917e+02,\n",
    "                    5.32152273e+02,5.62239392e+02,5.92149276e+02,6.21432841e+02,\n",
    "                    6.49689897e+02,6.76656485e+02,7.02242188e+02,7.26498589e+02,\n",
    "                    7.49537645e+02,7.71445217e+02,7.92234260e+02,8.11856675e+02,\n",
    "                    8.30259643e+02,8.47450653e+02,8.63535902e+02,8.78715875e+02,\n",
    "                    8.93246018e+02,9.07385213e+02,9.21354397e+02,9.35316717e+02,\n",
    "                    9.49378056e+02,9.63599599e+02,9.78013432e+02,9.92635544e+02],dtype=np.float32)\n",
    "        self.refpres_norm = (self.refpres-self.refpres.min())/(self.refpres.max()-self.refpres.min())*2 - 1\n",
    "\n",
    "        if 'train' in self.filepath:\n",
    "            self.is_validation = False\n",
    "            print(\"Training dataset, path is: {}\".format(self.filepath))\n",
    "        else:\n",
    "            self.is_validation = True\n",
    "            print(\"Validation dataset, path is: {}\".format(self.filepath))\n",
    "        self.cuda = cuda\n",
    "\n",
    "        self.add_refpres = add_refpres\n",
    "        # batch_idx_expanded =  [0,1,2,3...ntime*1024]\n",
    "        hdf = h5py.File(self.filepath, 'r')\n",
    "        self.ntimesteps = hdf['input_lev'].shape[0]//self.nloc\n",
    "        hdf.close()\n",
    "        print(\"Number of locations {}; time steps {}\".format(self.nloc, self.ntimesteps))\n",
    "        # indices_all = list(np.arange(self.ntimesteps*self.nloc))\n",
    "        # chunksize_tot = self.nloc*self.chunk_size\n",
    "        # indices_chunked = self.chunkize(indices_all,chunksize_tot,False) \n",
    "        # self.hdf = h5py.File(self.filepath, 'r')\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ntimesteps*self.nloc\n",
    "    \n",
    "    def __getitem__(self, batch_indices):\n",
    "        hdf = h5py.File(self.filepath, 'r')\n",
    "        # hdf = self.hdf\n",
    "        \n",
    "        x_lay_b = hdf['input_lev'][batch_indices,:]\n",
    "        x_sfc_b = hdf['input_sca'][batch_indices,:]\n",
    "        y_lay_b = hdf['output_lev'][batch_indices,:]\n",
    "        y_sfc_b = hdf['output_sca'][batch_indices,:]\n",
    "        \n",
    "        if self.add_refpres:\n",
    "            dim0,dim1,dim2 = x_lay_b.shape\n",
    "            # if self.norm==\"minmax\":\n",
    "            refpres_norm = self.refpres_norm.reshape((1,-1,1))\n",
    "            refpres_norm = np.repeat(refpres_norm, dim0,axis=0)\n",
    "            #self.x[:,:,nx-1] = refpres_norm\n",
    "            x_lay_b = np.concatenate((x_lay_b, refpres_norm),axis=2)\n",
    "            # self.x  = torch.cat((self.x,refpres_norm),dim=3)\n",
    "            del refpres_norm \n",
    "\n",
    "        hdf.close()\n",
    "\n",
    "        x_lay_b = torch.from_numpy(x_lay_b)\n",
    "        x_sfc_b = torch.from_numpy(x_sfc_b)\n",
    "        y_lay_b = torch.from_numpy(y_lay_b)\n",
    "        y_sfc_b = torch.from_numpy(y_sfc_b)\n",
    "\n",
    "        # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # x_lay_b = x_lay_b.to(device)\n",
    "        # x_sfc_b = x_sfc_b.to(device)\n",
    "        # y_lay_b = y_lay_b.to(device)\n",
    "        # sp = sp.to(device)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        return x_lay_b, x_sfc_b, y_lay_b, y_sfc_b\n",
    "\n",
    "def chunkize(filelist, chunk_size, shuffle_before_chunking=False, shuffle_after_chunking=True):\n",
    "    import random\n",
    "    # Takes a list, shuffles it (optional), and divides into chunks of length n\n",
    "    # (no concept of batches within this function, chunk size is given in number of samples)\n",
    "    def divide(filelist,chunk_size):\n",
    "        # looping till length l\n",
    "        for i in range(0, len(filelist), chunk_size): \n",
    "            yield filelist[i:i + chunk_size]  \n",
    "    if shuffle_before_chunking:\n",
    "        random.shuffle(filelist)\n",
    "        # we need the indices to be sorted within a chunk because these indices\n",
    "        # are used to index into the first dimension of a H5 file\n",
    "        for i in range(filelist):\n",
    "            filelist[i] = sorted(filelist[i])\n",
    "            \n",
    "    mylist = list(divide(filelist,chunk_size))\n",
    "    if shuffle_after_chunking:\n",
    "        random.shuffle(mylist)  \n",
    "    return mylist\n",
    "\n",
    "\n",
    "class BatchSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, num_samples_per_chunk, num_samples, shuffle=False):\n",
    "        self.num_samples_per_chunk = num_samples_per_chunk\n",
    "        self.num_samples = num_samples\n",
    "        indices_all = list(range(self.num_samples))\n",
    "        print(\"Shuffling the indices: {}\".format(shuffle))\n",
    "        self.indices_chunked = chunkize(indices_all,self.num_samples_per_chunk,\n",
    "                                        shuffle_before_chunking=False,\n",
    "                                        shuffle_after_chunking=shuffle)\n",
    "        #print(\"indices chunked [0]\", self.indices_chunked[0])\n",
    "        # one item is one chunk, consisting of chunk_factor*batch_size samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.indices_chunked)\n",
    "        # for batch in self.indices_chunked:\n",
    "        #     yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1725a2ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset, path is: /network/group/aopp/predict/HMC009_UKKONEN_CLIMSIM/ClimSim_data/ClimSim_low-res-expanded/train/preprocessed/train_first4months.h5\n",
      "Number of locations 384; time steps 8637\n",
      "Shuffling the indices: True\n"
     ]
    }
   ],
   "source": [
    "shuffle_data = True \n",
    "\n",
    "train_locs = nloc = 384\n",
    "batch_size = train_locs \n",
    "\n",
    "# To improve IO, which is a bottleneck, increase the batch size by a factor of chunk_factor and \n",
    "# load this many batches at once. These chunks then need to be manually split into batches \n",
    "# within the data iteration loop    \n",
    "\n",
    "# chunk size in number of batches\n",
    "#chunk_size = 72 # one day (3 time steps in an hour, 72 in a day)\n",
    "#chunk_size = 360     \n",
    "chunk_size = 720 # 10 days\n",
    "# chunk size in number of elements\n",
    "num_samples_per_chunk = chunk_size*batch_size\n",
    "\n",
    "train_data = generator_xy(data_path, nloc=train_locs, add_refpres=add_refpres)\n",
    "\n",
    "batch_sampler_tr = BatchSampler(num_samples_per_chunk,\n",
    "                                num_samples=train_data.__len__(), shuffle=shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c4838260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27648"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72*384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "795048a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "use_val = False \n",
    "\n",
    "num_workers = 2\n",
    "prefetch_factor = 1\n",
    "pin = False\n",
    "persistent=False\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, num_workers=num_workers, sampler=batch_sampler_tr, \n",
    "                          batch_size=None,batch_sampler=None,prefetch_factor=prefetch_factor, \n",
    "                          pin_memory=pin, persistent_workers=persistent)\n",
    "\n",
    "if use_val:\n",
    "    val_loader = DataLoader(dataset=val_data, num_workers=num_workers,sampler=batch_sampler_val,\n",
    "                            batch_size=None,batch_sampler=None,prefetch_factor=prefetch_factor, \n",
    "                            pin_memory=pin, persistent_workers=persistent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d6e76580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1679"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a90cae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available() \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "\n",
    "if cuda:\n",
    "    mp_autocast = True \n",
    "    # if torch.cuda.is_bf16_supported(): \n",
    "    #     dtype=torch.bfloat16 \n",
    "    #     use_scaler = False\n",
    "    # else:\n",
    "    #     dtype=torch.float16\n",
    "    #     use_scaler = True \n",
    "    dtype=torch.float16\n",
    "    use_scaler = True \n",
    "else:\n",
    "    mp_autocast = False\n",
    "    use_scaler = False\n",
    "    \n",
    "    \n",
    "if use_scaler:\n",
    "    # scaler = torch.amp.GradScaler(autocast = True)\n",
    "    scaler = torch.amp.GradScaler(device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92984f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "78b54b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_mse(y_true_lay, y_true_sfc, y_pred_lay, y_pred_sfc):\n",
    "    mse1 = torch.mean(torch.square(y_pred_lay - y_true_lay))\n",
    "    mse2 = torch.mean(torch.square(y_pred_sfc - y_true_sfc))\n",
    "    return (mse1+mse2)/2\n",
    "\n",
    "loss_fn = my_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ec5df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8fa03d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.regression import R2Score\n",
    "import time\n",
    "num_epochs = 2\n",
    "\n",
    "autoregressive = False\n",
    "\n",
    "if not autoregressive:\n",
    "    timewindow = 1\n",
    "    timestep_scheduling=False\n",
    "else:\n",
    "    timewindow = 3\n",
    "    timestep_scheduling=True\n",
    "    timestep_schedule = np.arange(num_epochs)\n",
    "    timestep_schedule[:] = timewindow\n",
    "\n",
    "    if timestep_scheduling:\n",
    "        timestep_schedule[0:3] = 1\n",
    "        timestep_schedule[3:4] = timewindow-1\n",
    "        timestep_schedule[4:] = timewindow\n",
    "        timestep_schedule[5:] = timewindow+1\n",
    "        timestep_schedule[6:] = timewindow+2\n",
    "\n",
    "    \n",
    "use_wandb = False\n",
    "\n",
    "class model_train_eval:\n",
    "    def __init__(self, dataloader, model, autoregressive=True, train=True):\n",
    "        super().__init__()\n",
    "        self.loader = dataloader\n",
    "        self.train = train\n",
    "        self.report_freq = 800\n",
    "        self.model = model \n",
    "        self.autoregressive = autoregressive\n",
    "        if self.autoregressive:\n",
    "            self.model.reset_states()\n",
    "        self.metric_R2 =  R2Score().to(device) \n",
    "        self.metrics= {'loss': 0, 'mean_squared_error': 0,  # the latter is just MSE\n",
    "                        'mean_absolute_error': 0, 'R2' : 0}\n",
    "\n",
    "    def eval_one_epoch(self, epoch, timewindow=1):\n",
    "        report_freq = self.report_freq\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0\n",
    "        epoch_mse = 0.0; epoch_mae = 0.0\n",
    "        t_comp =0 \n",
    "        if self.autoregressive:\n",
    "            preds_lay = []; preds_sfc = []\n",
    "            targets_lay = []; targets_sfc = [] \n",
    "        t0_it = time.time()\n",
    "        j = 0; k = 0; k2=2    \n",
    "        if self.autoregressive:\n",
    "            loss_update_start_index = 60\n",
    "        else:\n",
    "            loss_update_start_index = 0\n",
    "        for i,data in enumerate(self.loader):\n",
    "            inputs_lay_chunks, inputs_sfc_chunks, targets_lay_chunks, targets_sfc_chunks = data\n",
    "            inputs_lay_chunks   = inputs_lay_chunks.to(device)\n",
    "            inputs_sfc_chunks   = inputs_sfc_chunks.to(device)\n",
    "            targets_sfc_chunks  = targets_sfc_chunks.to(device)\n",
    "            targets_lay_chunks  = targets_lay_chunks.to(device)\n",
    "            \n",
    "            inputs_lay_chunks    = torch.split(inputs_lay_chunks, batch_size)\n",
    "            inputs_sfc_chunks    = torch.split(inputs_sfc_chunks, batch_size)\n",
    "            targets_sfc_chunks   = torch.split(targets_sfc_chunks, batch_size)\n",
    "            targets_lay_chunks   = torch.split(targets_lay_chunks, batch_size)\n",
    "         \n",
    "            # to speed-up IO, we loaded chunks=many batches, which now need to be divided into batches\n",
    "            for ichunk in range(len(inputs_lay_chunks)):\n",
    "                inputs_lay = inputs_lay_chunks[ichunk]\n",
    "                inputs_sfc = inputs_sfc_chunks[ichunk]\n",
    "                target_lay = targets_lay_chunks[ichunk]\n",
    "                target_sfc = targets_sfc_chunks[ichunk]\n",
    "\n",
    "                tcomp0= time.time()\n",
    "                    \n",
    "                if mp_autocast:\n",
    "                    with torch.autocast(device_type=device.type, dtype=dtype):\n",
    "                        pred_lay, pred_sfc = self.model(inputs_lay, inputs_sfc)\n",
    "                else:\n",
    "                    pred_lay, pred_sfc = self.model(inputs_lay, inputs_sfc)\n",
    "                    \n",
    "                if self.autoregressive:\n",
    "                    # In the autoregressive training case are gathering many time steps before computing loss\n",
    "                    preds_lay.append(pred_lay)\n",
    "                    preds_sfc.append(pred_sfc)\n",
    "                    targets_lay.append(target_lay)\n",
    "                    targets_sfc.append(target_sfc)\n",
    "                else:\n",
    "                    preds_lay = pred_lay\n",
    "                    preds_sfc = pred_sfc \n",
    "                    targets_lay = target_lay\n",
    "                    targets_sfc = target_sfc\n",
    "                    \n",
    "                    \n",
    "                if (not self.autoregressive) or (self.autoregressive and (j+1) % timewindow==0):\n",
    "            \n",
    "                    if self.autoregressive:\n",
    "                        preds_lay   = torch.stack(preds_lay)\n",
    "                        preds_sfc   = torch.stack(preds_sfc)\n",
    "                        targets_lay = torch.stack(targets_lay)\n",
    "                        targets_sfc = torch.stack(targets_sfc)\n",
    "        \n",
    "                    if mp_autocast:\n",
    "                        with torch.autocast(device_type=device.type, dtype=dtype):\n",
    "                            loss = loss_fn(targets_lay, targets_sfc, preds_lay, preds_sfc)\n",
    "                    else:\n",
    "                        loss = loss_fn(targets_lay, targets_sfc, preds_lay, preds_sfc)\n",
    "            \n",
    "                    if self.train:\n",
    "                        if use_scaler:\n",
    "                            scaler.scale(loss).backward()\n",
    "                            scaler.step(optimizer)\n",
    "                            scaler.update()\n",
    "                        else:\n",
    "                            loss.backward()       \n",
    "                            optimizer.step()\n",
    "            \n",
    "                        optimizer.zero_grad()\n",
    "                            \n",
    "                    running_loss    += loss.item()\n",
    "                    #mae             = metrics.mean_absolute_error(targets_lay, preds_lay)\n",
    "                    if j>loss_update_start_index:\n",
    "                        with torch.no_grad():\n",
    "                            epoch_loss      += loss.item()\n",
    "                            #epoch_energy    += energy.item()\n",
    "                            #epoch_mseu      += mse.item()\n",
    "                            #epoch_mae       += mae.item()\n",
    "                        \n",
    "                           # yto, ypo =  denorm_func(targets_lay, preds_lay)\n",
    "                            # -------------- TO-DO:  DE-NORM OUTPUT --------------\n",
    "                            yto, ypo = targets_lay, preds_lay\n",
    "                            self.metric_R2.update(ypo.reshape((-1,ny)), yto.reshape((-1,ny)))\n",
    "                           # if track_ks:\n",
    "                           #     if (j+1) % max(timewindow*4,12)==0:\n",
    "                           #         epoch_ks += kolmogorov_smirnov(yto,ypo).item()\n",
    "                           #         k2 += 1\n",
    "                            k += 1\n",
    "                    if self.autoregressive:\n",
    "                        preds_lay = []; preds_sfc = []\n",
    "                        targets_lay = []; targets_sfc = [] \n",
    "                    if self.autoregressive: \n",
    "                        model.detach_states()\n",
    "                \n",
    "                t_comp += time.time() - tcomp0\n",
    "                # # print statistics \n",
    "                if j % report_freq == (report_freq-1): # print every 200 minibatches\n",
    "                    elaps = time.time() - t0_it\n",
    "                    running_loss = running_loss / (report_freq/timewindow)\n",
    "                    #running_energy = running_energy / (report_freq/timewindow)\n",
    "                    r2raw = self.metric_R2.compute()\n",
    "                    print(\"[{:d}, {:d}] Loss: {:.2e}  runningR2: {:.2f}, elapsed {:.1f}s (compute {:.1f})\" .format(epoch + 1, \n",
    "                                                    j+1, running_loss, r2raw, elaps, t_comp))\n",
    "                    running_loss = 0.0\n",
    "                    running_energy = 0.0\n",
    "                    t0_it = time.time()\n",
    "                    t_comp = 0\n",
    "                j += 1\n",
    "\n",
    "        self.metrics['loss'] =  epoch_loss / k\n",
    "        self.metrics['mean_squared_error'] = epoch_loss / k\n",
    "\n",
    "        #self.metrics['energymetric'] = epoch_energy / k\n",
    "        #self.metrics['mean_absolute_error'] = epoch_mae / k\n",
    "        #self.metrics['ks'] =  epoch_ks / k2\n",
    "        self.metrics['R2'] = self.metric_R2.compute()\n",
    "        self.metric_R2.reset()\n",
    "        if self.autoregressive:\n",
    "            self.model.reset_states()\n",
    "        \n",
    "        datatype = \"TRAIN\" if self.train else \"VAL\"\n",
    "        print('Epoch {} {} loss: {:.2e}  MSE: {:.2e}  R2: {:.2f}'.format(epoch+1, datatype, self.metrics['loss'], \n",
    "                                                                        self.metrics['mean_squared_error'], \n",
    "                                                                        self.metrics['R2']))\n",
    "\n",
    "    if cuda: torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f48c19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training rollout timesteps: 1 \n",
      "[1, 800] Loss: 2.79e-03  runningR2: 0.17, elapsed 13.7s (compute 4.0)\n",
      "[1, 1600] Loss: 2.71e-03  runningR2: 0.18, elapsed 6.2s (compute 4.0)\n",
      "[1, 2400] Loss: 2.69e-03  runningR2: 0.18, elapsed 4.3s (compute 4.0)\n",
      "[1, 3200] Loss: 2.74e-03  runningR2: 0.18, elapsed 6.1s (compute 4.0)\n",
      "[1, 4000] Loss: 2.68e-03  runningR2: 0.18, elapsed 4.3s (compute 4.0)\n",
      "[1, 4800] Loss: 2.75e-03  runningR2: 0.18, elapsed 4.8s (compute 3.8)\n",
      "[1, 5600] Loss: 2.72e-03  runningR2: 0.18, elapsed 4.3s (compute 3.9)\n",
      "[1, 6400] Loss: 2.72e-03  runningR2: 0.18, elapsed 5.6s (compute 4.0)\n",
      "[1, 7200] Loss: 2.66e-03  runningR2: 0.18, elapsed 5.5s (compute 4.0)\n",
      "[1, 8000] Loss: 2.65e-03  runningR2: 0.19, elapsed 4.3s (compute 4.0)\n",
      "Epoch 1 TRAIN loss: 2.71e-03  MSE: 2.71e-03  R2: 0.19\n",
      "Epoch 1/2 complete, took 62.49 seconds, autoreg window was 1\n",
      "Epoch 2 Training rollout timesteps: 1 \n",
      "[2, 800] Loss: 2.63e-03  runningR2: 0.19, elapsed 12.9s (compute 3.8)\n",
      "[2, 1600] Loss: 2.54e-03  runningR2: 0.20, elapsed 6.1s (compute 3.8)\n",
      "[2, 2400] Loss: 2.53e-03  runningR2: 0.20, elapsed 4.3s (compute 4.1)\n",
      "[2, 3200] Loss: 2.59e-03  runningR2: 0.20, elapsed 5.7s (compute 3.9)\n",
      "[2, 4000] Loss: 2.55e-03  runningR2: 0.20, elapsed 4.3s (compute 3.9)\n",
      "[2, 4800] Loss: 2.61e-03  runningR2: 0.20, elapsed 4.9s (compute 4.0)\n",
      "[2, 5600] Loss: 2.59e-03  runningR2: 0.20, elapsed 4.6s (compute 4.0)\n",
      "[2, 6400] Loss: 2.60e-03  runningR2: 0.20, elapsed 4.7s (compute 4.0)\n",
      "[2, 7200] Loss: 2.52e-03  runningR2: 0.20, elapsed 5.9s (compute 4.1)\n",
      "[2, 8000] Loss: 2.53e-03  runningR2: 0.20, elapsed 5.2s (compute 4.0)\n",
      "Epoch 2 TRAIN loss: 2.56e-03  MSE: 2.56e-03  R2: 0.20\n",
      "Epoch 2/2 complete, took 62.00 seconds, autoreg window was 1\n"
     ]
    }
   ],
   "source": [
    "train_runner = model_train_eval(train_loader, model, autoregressive, train=True)\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    if timestep_scheduling:\n",
    "        timewindoww=timestep_schedule[epoch]            \n",
    "    else:\n",
    "        timewindoww=timewindow\n",
    "        \n",
    "    print(\"Epoch {} Training rollout timesteps: {} \".format(epoch+1, timewindoww))\n",
    "    train_runner.eval_one_epoch(epoch, timewindoww)\n",
    "    \n",
    "    if use_wandb: wandb.log(train_runner.metrics)\n",
    "    \n",
    "    if use_val:\n",
    "        if epoch%2:\n",
    "            print(\"VALIDATION..\")\n",
    "            val_runner.eval_one_epoch(epoch, timewindoww)\n",
    "\n",
    "            losses_val = {\"val_\"+k: v for k, v in val_runner.metrics.items()}\n",
    "            if use_wandb: wandb.log(losses_val)\n",
    "\n",
    "            val_loss = losses_val[\"val_loss\"]\n",
    "\n",
    "            # MODEL CHECKPOINT IF VALIDATION LOSS IMPROVED\n",
    "            if save_model and val_loss < best_val_loss:\n",
    "              torch.save({\n",
    "                          'epoch': epoch,\n",
    "                          'model_state_dict': model.state_dict(),\n",
    "                          'optimizer_state_dict': optimizer.state_dict(),\n",
    "                          'val_loss': val_loss,\n",
    "                          }, SAVE_PATH)  \n",
    "              best_val_loss = val_loss \n",
    "              \n",
    "    print('Epoch {}/{} complete, took {:.2f} seconds, autoreg window was {}'.format(epoch+1,num_epochs,time.time() - t0,timewindoww))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e45eb52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_torch_cu121",
   "language": "python",
   "name": "py311_torch_cu121"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
